# ğŸ”— Cross-API Bench: Multi-Provider Orchestration Benchmark

<div align="center">

**The first benchmark for evaluating AI agents on cross-API orchestration tasks**

[![Tasks](https://img.shields.io/badge/Tasks-103-blue?style=for-the-badge)]()
[![Tools](https://img.shields.io/badge/Tools-76-green?style=for-the-badge)]()
[![APIs](https://img.shields.io/badge/APIs-5-orange?style=for-the-badge)]()
[![AgentBeats](https://img.shields.io/badge/AgentBeats-Compatible-success?style=for-the-badge)]()

</div>

---

## ğŸ¯ What is Cross-API Orchestration?

Unlike single-API benchmarks, **Cross-API Bench** evaluates agents on tasks that require **chaining operations across multiple API providers**:

```
ğŸ“‹ Task: "Compile Q4 metrics and notify stakeholders"

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚   Notion    â”‚ â”€â”€â–¶ â”‚Google Drive â”‚ â”€â”€â–¶ â”‚Google Sheetsâ”‚
  â”‚  (search)   â”‚     â”‚ (get docs)  â”‚     â”‚ (get data)  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                                       â”‚
         â–¼                                       â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Google Docs â”‚ â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ â”‚   Gmail     â”‚
  â”‚ (create)    â”‚                         â”‚  (draft)    â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š 3D Scoring System

| Metric | Weight | What It Measures |
|--------|--------|-----------------|
| **Action Match** | 50% | Did the agent call the right tools? |
| **Argument Quality** | 40% | Were parameters correct? |
| **Efficiency** | 10% | How many steps were used? |

```
Total Score = (Action Ã— 0.5) + (Argument Ã— 0.4) + (Efficiency Ã— 0.1)
```

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.13+ with [uv](https://github.com/astral-sh/uv)
- Docker (optional)

### Run Locally

```bash
# Clone & install
git clone https://github.com/AX-AIAgents/cross-api-bench.git
cd cross-api-bench && uv sync

# Set API key
export OPENAI_API_KEY=your_key

# Run evaluation
uv run agentbeats-run scenario.toml
```

### Run with Docker

```bash
docker compose up
```

**Pre-built Docker Images:**
- Green Agent (Evaluator): `ghcr.io/ax-aiagents/green-agent:main`
- Purple Agent (Participant): `ghcr.io/ax-aiagents/purple-agent:main`

---



---

## ğŸ”§ API Coverage

| Provider | Tools | Example Operations |
|----------|-------|-------------------|
| **Notion** | 21 | Search, create pages, append blocks |
| **Gmail** | 19 | Search, read, draft, send emails |
| **Google Drive** | 31 | Search, create docs/sheets/slides |
| **YouTube** | 3 | Get transcripts, video info |
| **Web Search** | 2 | Serper search, URL scraping |

---

## ğŸ“ˆ Benchmark Results

| Agent | Action | Argument | Efficiency | **Total** |
|-------|--------|----------|------------|-----------|
| GPT-4o-mini | 28.57% | 21.43% | 57.14% | **28.57%** |
| *Your Agent* | ? | ? | ? | ? |

---

## ğŸ“„ Documentation

- [**ABSTRACT.md**](ABSTRACT.md) - Academic paper format
- [**DIAGRAM.md**](DIAGRAM.md) - Architecture & flow diagrams

---

## ğŸ“œ License

MIT License

---

<div align="center">

**Built for AgentBeats Benchmark Competition 2026**

*5 APIs â€¢ 76 Tools â€¢ 103 Tasks â€¢ 3D Scoring*

</div>